# Dataset configuration
data_path: ./dataset
dataset: train_data
field_separator: "\t"
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
LABEL_FIELD: label
TIME_FIELD: timestamp

load_col:
    inter: ["user_id", "item_id", "label", "timestamp"]

# Model arguments
model_args:
    EASE:
        reg_weight: 500               # Regularization weight
    LightGCN:
        embedding_size: 64            # 임베딩 크기
        n_layers: 3                   # Graph propagation layers
        reg_weight: 1e-4              # Regularization weight
    RecVAE:
        latent_dim: 200               # VAE의 잠재 공간 크기
        hidden_dims: [600, 300]       # 인코더/디코더의 히든 레이어 크기
        dropout_prob: 0.5             # 드롭아웃 확률
        anneal_cap: 0.2               # KL 다이버전스 학습 시 가중치
        total_anneal_steps: 200000    # KL 다이버전스 학습 시 단계
    DeepFM:
        embedding_dim: 32
        mlp_dims: [30, 20, 10]
        drop_rate: 0.1

# Training configuration
train_batch_size: 2048
learning_rate: 0.001  

# Evaluation configuration
eval_args:
    split: {'RS': [0.8, 0.1, 0.1]}
    group_by: user
    order: RO
    mode: {'valid': 'full', 'test': 'full'}
    save_result: True
    disable_tqdm: True

checkpoint_dir: ./saved
checkpoint_file: "{model_name}-{timestamp}.pth"

metrics: ['Recall', 'Precision', 'MAP', 'NDCG']
topk: [5, 10]
valid_metric: Recall@10
